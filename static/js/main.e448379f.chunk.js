(this["webpackJsonpophthalmology-ai"]=this["webpackJsonpophthalmology-ai"]||[]).push([[0],{71:function(e){e.exports=JSON.parse('[{"id":1,"title":"Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning","url":"https://www.nature.com/articles/s41551-018-0195-0","download-url":"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46425.pdf","abstract":"Traditionally, medical discoveries are made by observing associations, making hypotheses from them and then designing and running experiments to test the hypotheses. However, with medical images, observing and quantifying associations can often be difficult because of the wide variety of features, patterns, colours, values and shapes that are present in real data. Here, we show that deep learning can extract new knowledge from retinal fundus images. Using deep-learning models trained on data from 284,335 patients and validated on two independent datasets of 12,026 and 999 patients, we predicted cardiovascular risk factors not previously thought to be present or quantifiable in retinal images, such as age (mean absolute error within 3.26 years), gender (area under the receiver operating characteristic curve (AUC)\u2009=\u20090.97), smoking status (AUC\u2009=\u20090.71), systolic blood pressure (mean absolute error within 11.23\u2009mmHg) and major adverse cardiac events (AUC\u2009=\u20090.70). We also show that the trained deep-learning models used anatomical features, such as the optic disc or blood vessels, to generate each prediction.","authors":"Ryan Poplin, Avinash V. Varadarajan, Katy Blumer, Yun Liu, Michael V. McConnell, Greg S. Corrado, Lily Peng, Dale R. Webster","publication_type":"PEER-REVIEWED-JOURNAL","publications_tags":"NEW-RESEARCH","application_areas":"DIAGNOSTICS","medical_areas":"CARDIOVASCULAR-RISK-FACTORS","modalities":"FUNDUS-PHOTOGRAPHS","datasets":"EYEPACS-2K, UK-BIOBANK","patients":284335,"comment":"Landmark paper looking at the idea of deriving non-ophthalmological outcomes from retinal images","DOI":"https://doi.org/10.1038/s41551-018-0195-0"},{"id":2,"title":"Predicting conversion to wet age-related macular degeneration using deep learning","url":"https://www.nature.com/articles/s41591-020-0867-7","download-url":"https://www.blog.google/documents/76/Full_text__41591_2020_867_OnlinePDF_2_2.pdf","abstract":"Progression to exudative \u2018wet\u2019 age-related macular degeneration (exAMD) is a major cause of visual deterioration. In patients diagnosed with exAMD in one eye, we introduce an artificial intelligence (AI) system to predict progression to exAMD in the second eye. By combining models based on three-dimensional (3D) optical coherence tomography images and corresponding automatic tissue maps, our system predicts conversion to exAMD within a clinically actionable 6-month time window, achieving a per-volumetric-scan sensitivity of 80% at 55% specificity, and 34% sensitivity at 90% specificity. This level of performance corresponds to true positives in 78% and 41% of individual eyes, and false positives in 56% and 17% of individual eyes at the high sensitivity and high specificity points, respectively. Moreover, we show that automatic tissue segmentation can identify anatomical changes before conversion and high-risk subgroups. This AI system overcomes substantial interobserver variability in expert predictions, performing better than five out of six experts, and demonstrates the potential of using AI to predict disease progression. In individuals diagnosed with age-related macular degeneration in one eye, a deep learning model can predict progression to the \u2018wet\u2019, sight-threatening form of the disease in the second eye within a 6-month time frame.","authors":"Jason Yim, Reena Chopra, Terry Spitz, Jim Winkens, Annette Obika, Christopher Kelly, Harry Askham, Marko Lukic, Josef Huemer, Katrin Fasler, Gabriella Moraes, Clemens Meyer, Marc Wilson, Jonathan Dixon, Cian Hughes, Geraint Rees, Peng T. Khaw, Alan Karthikesalingam, Dominic King, Demis Hassabis, Mustafa Suleyman, Trevor Back, Joseph R. Ledsam, Pearse A. Keane, Jeffrey De Fauw","publication_type":"PEER-REVIEWED-JOURNAL","publications_tags":"NEW-RESEARCH","application_areas":"AMD","medical_areas":"PROGNOSTICS","modalities":"OCT, SLO","datasets":"PRIVATE","patients":2795,"comment":"","DOI":""},{"id":3,"title":"AI papers in ophthalmology made simple","url":"https://www.nature.com/articles/s41433-020-0929-6","download-url":"https://www.nature.com/articles/s41433-020-0929-6https://www.nature.com/articles/s41433-020-0929-6.pdf","abstract":"","authors":"Sohee Jeon, Yun Liu, Ji-Peng Olivia Li, Dale Webster, Lily Peng, Daniel Ting","publication_type":"EDITORIAL","publications_tags":"EXPLAINER","application_areas":"","medical_areas":"","modalities":"","datasets":"","patients":"null","comment":"","DOI":"\'Handy explainer to help clinicians understand and critic AI publications\'"},{"id":4,"title":"Development and Validation of a Deep Learning System for Diabetic Retinopathy and Related Eye Diseases Using Retinal Images From Multiethnic Populations With Diabetes","url":"https://jamanetwork.com/article.aspx?doi=10.1001/jama.2017.18152","download-url":"","abstract":"Importance  A deep learning system (DLS) is a machine learning technology with potential for screening diabetic retinopathy and related eye diseases. Objective  To evaluate the performance of a DLS in detecting referable diabetic retinopathy, vision-threatening diabetic retinopathy, possible glaucoma, and age-related macular degeneration (AMD) in community and clinic-based multiethnic populations with diabetes. Design, Setting, and Participants  Diagnostic performance of a DLS for diabetic retinopathy and related eye diseases was evaluated using 494\u202f661 retinal images. A DLS was trained for detecting diabetic retinopathy (using 76\u202f370 images), possible glaucoma (125\u202f189 images), and AMD (72\u202f610 images), and performance of DLS was evaluated for detecting diabetic retinopathy (using 112\u202f648 images), possible glaucoma (71\u202f896 images), and AMD (35\u202f948 images). Training of the DLS was completed in May 2016, and validation of the DLS was completed in May 2017 for detection of referable diabetic retinopathy (moderate nonproliferative diabetic retinopathy or worse) and vision-threatening diabetic retinopathy (severe nonproliferative diabetic retinopathy or worse) using a primary validation data set in the Singapore National Diabetic Retinopathy Screening Program and 10 multiethnic cohorts with diabetes. Exposures  Use of a deep learning system. Main Outcomes and Measures  Area under the receiver operating characteristic curve (AUC) and sensitivity and specificity of the DLS with professional graders (retinal specialists, general ophthalmologists, trained graders, or optometrists) as the reference standard. Results  In the primary validation dataset (n\u2009=\u200914\u202f880 patients; 71\u202f896 images; mean [SD] age, 60.2 [2.2] years; 54.6% men), the prevalence of referable diabetic retinopathy was 3.0%; vision-threatening diabetic retinopathy, 0.6%; possible glaucoma, 0.1%; and AMD, 2.5%. The AUC of the DLS for referable diabetic retinopathy was 0.936 (95% CI, 0.925-0.943), sensitivity was 90.5% (95% CI, 87.3%-93.0%), and specificity was 91.6% (95% CI, 91.0%-92.2%). For vision-threatening diabetic retinopathy, AUC was 0.958 (95% CI, 0.956-0.961), sensitivity was 100% (95% CI, 94.1%-100.0%), and specificity was 91.1% (95% CI, 90.7%-91.4%). For possible glaucoma, AUC was 0.942 (95% CI, 0.929-0.954), sensitivity was 96.4% (95% CI, 81.7%-99.9%), and specificity was 87.2% (95% CI, 86.8%-87.5%). For AMD, AUC was 0.931 (95% CI, 0.928-0.935), sensitivity was 93.2% (95% CI, 91.1%-99.8%), and specificity was 88.7% (95% CI, 88.3%-89.0%). For referable diabetic retinopathy in the 10 additional datasets, AUC range was 0.889 to 0.983 (n\u2009=\u200940\u202f752 images). Conclusions and Relevance  In this evaluation of retinal images from multiethnic cohorts of patients with diabetes, the DLS had high sensitivity and specificity for identifying diabetic retinopathy and related eye diseases. Further research is necessary to evaluate the applicability of the DLS in health care settings and the utility of the DLS to improve vision outcomes.","authors":"Daniel Shu Wei Ting, Carol Yim-Lui Cheung, Gilbert Lim, Gavin Siew Wei Tan, Nguyen D. Quang, Alfred Gan, Haslina Hamzah, Renata Garcia-Franco, Ian Yew San Yeo, Shu Yen Lee, Edmund Yick Mun Wong, Charumathi Sabanayagam, Mani Baskaran, Farah Ibrahim, Ngiap Chuan Tan, Eric A. Finkelstein, Ecosse L. Lamoureux, Ian Y. Wong, Neil M. Bressler, Sobha Sivaprasad, Rohit Varma, Jost B. Jonas, Ming Guang He, Ching-Yu Cheng, Gemmy Chui Ming Cheung, Tin Aung, Wynne Hsu, Mong Li Lee, Tien Yin Wong","publication_type":"PEER-REVIEWED-JOURNAL","publications_tags":"NEW-RESEARCH","application_areas":"DIAGNOSTICS","medical_areas":"DIABETIC-RETINOPATHY, GLAUCOMA","modalities":"FUNDUS-PHOTOGRAPHS","datasets":"","patients":null,"comment":"","DOI":""}]')},87:function(e,a,i){},88:function(e,a,i){},97:function(e,a,i){"use strict";i.r(a);var t=i(4),n=i(0),s=i.n(n),o=i(26),r=i.n(o),c=(i(87),i(88),i(89),i.p+"static/media/cybersight-logo.46d41ccb.png"),l=i(112),d=i(114),h=i(113),p=i(115),u=i(64),g=i(71);i(90);var m=function(){var e=function(e){var a=e.color;return Object(t.jsx)("hr",{style:{color:a,backgroundColor:a,height:3}})};return Object(t.jsx)("div",{className:"App",children:Object(t.jsxs)(l.a,{children:[Object(t.jsxs)(d.a,{as:"h1",textAlign:"center",children:[Object(t.jsx)(h.a,{src:c}),Object(t.jsx)(d.a.Content,{children:"Awesome AI in Ophthalmology"}),Object(t.jsx)(d.a.Subheader,{children:"Powered by Cybersight-AI"})]}),Object(t.jsxs)(p.a,{padded:"very",raised:!0,size:"large",children:[Object(t.jsxs)(d.a,{as:"h3",dividing:!0,children:[Object(t.jsx)(u.a,{name:"question circle"}),Object(t.jsxs)(d.a.Content,{children:["About",Object(t.jsx)(d.a.Subheader,{children:"What is AI in Ophthalmology all about?"})]})]}),Object(t.jsxs)(p.a,{basic:!0,size:"medium",children:["Artificial Intelligence in Ophthalmology is an ever-growing field. The aim of this site is to provide a source of truth for all resources involving AI in Ophthalmology, to better understand the field, and build a community in which we can better help the world see.",Object(t.jsx)("br",{}),Object(t.jsx)(e,{color:"black"}),Object(t.jsx)(p.a,{basic:!0,size:"large",children:g.map((function(e){return Object(t.jsx)("li",{children:Object(t.jsxs)("div",{children:[Object(t.jsxs)(d.a,{as:"h3",children:[e.title,Object(t.jsx)(d.a.Subheader,{children:Object(t.jsx)("a",{href:e.url,children:"Visit Publication Here"})})]}),Object(t.jsxs)(p.a,{basic:!0,size:"medium",children:["Authors: ",e.authors]}),Object(t.jsx)(p.a,{basic:!0,size:"medium",children:e.abstract})]})},e.id)}))})]})]})]})})},b=function(e){e&&e instanceof Function&&i.e(3).then(i.bind(null,116)).then((function(a){var i=a.getCLS,t=a.getFID,n=a.getFCP,s=a.getLCP,o=a.getTTFB;i(e),t(e),n(e),s(e),o(e)}))};r.a.render(Object(t.jsx)(s.a.StrictMode,{children:Object(t.jsx)(m,{})}),document.getElementById("root")),b()}},[[97,1,2]]]);
//# sourceMappingURL=main.e448379f.chunk.js.map